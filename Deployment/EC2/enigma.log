*** Starting uWSGI 2.0.19.1 (64bit) on [Sun Jan 10 14:50:52 2021] ***
compiled with version: 9.3.0 on 10 January 2021 08:34:57
os: Linux-5.4.0-1029-aws #30-Ubuntu SMP Tue Oct 20 10:06:38 UTC 2020
nodename: ip-172-31-29-101
machine: x86_64
clock source: unix
detected number of CPU cores: 2
current working directory: /home/ubuntu/enigma
detected binary path: /home/ubuntu/venv/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
your processes number limit is 31409
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to UNIX address enigma.sock fd 3
Python version: 3.8.5 (default, Jul 28 2020, 12:59:40)  [GCC 9.3.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x55e53b3b5bc0
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 437520 bytes (427 KB) for 5 cores
*** Operational MODE: preforking ***
WSGI app 0 (mountpoint='') ready in 3 seconds on interpreter 0x55e53b3b5bc0 pid: 2173 (default app)
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI master process (pid: 2173)
spawned uWSGI worker 1 (pid: 2187, cores: 1)
spawned uWSGI worker 2 (pid: 2188, cores: 1)
spawned uWSGI worker 3 (pid: 2189, cores: 1)
spawned uWSGI worker 4 (pid: 2190, cores: 1)
spawned uWSGI worker 5 (pid: 2191, cores: 1)
[pid: 2190|app: 0|req: 1/1] 103.42.179.202 () {28 vars in 348 bytes} [Sun Jan 10 15:08:50 2021] GET /manager/html/ => generated 232 bytes in 4 msecs (HTTP/1.0 404) 2 headers in 87 bytes (1 switches on core 0)
[pid: 2191|app: 0|req: 1/2] 104.198.187.86 () {26 vars in 280 bytes} [Sun Jan 10 15:11:49 2021] GET /login => generated 232 bytes in 3 msecs (HTTP/1.0 404) 2 headers in 87 bytes (1 switches on core 0)
[pid: 2190|app: 0|req: 2/3] 104.198.187.86 () {28 vars in 346 bytes} [Sun Jan 10 15:11:49 2021] GET /manager/html => generated 232 bytes in 0 msecs (HTTP/1.0 404) 2 headers in 87 bytes (2 switches on core 0)
[pid: 2191|app: 0|req: 2/4] 222.186.160.243 () {40 vars in 565 bytes} [Sun Jan 10 15:26:50 2021] GET / => generated 232 bytes in 0 msecs (HTTP/1.1 404) 2 headers in 87 bytes (1 switches on core 0)
[pid: 2191|app: 0|req: 3/5] 192.241.224.88 () {34 vars in 381 bytes} [Sun Jan 10 15:52:48 2021] GET / => generated 232 bytes in 0 msecs (HTTP/1.1 404) 2 headers in 87 bytes (1 switches on core 0)
[pid: 2191|app: 0|req: 4/6] 198.143.146.34 () {34 vars in 475 bytes} [Sun Jan 10 15:55:34 2021] GET / => generated 232 bytes in 0 msecs (HTTP/1.1 404) 2 headers in 87 bytes (1 switches on core 0)
[pid: 2191|app: 0|req: 5/7] 41.215.12.74 () {32 vars in 449 bytes} [Sun Jan 10 16:54:39 2021] GET / => generated 232 bytes in 0 msecs (HTTP/1.1 404) 2 headers in 87 bytes (1 switches on core 0)
[pid: 2187|app: 0|req: 1/8] 69.25.58.18 () {32 vars in 441 bytes} [Sun Jan 10 17:27:40 2021] GET / => generated 232 bytes in 2 msecs (HTTP/1.1 404) 2 headers in 87 bytes (1 switches on core 0)
[pid: 2191|app: 0|req: 6/9] 170.39.186.106 () {36 vars in 511 bytes} [Sun Jan 10 18:55:38 2021] GET /.env => generated 232 bytes in 1 msecs (HTTP/1.1 404) 2 headers in 87 bytes (1 switches on core 0)
[pid: 2190|app: 0|req: 3/10] 170.39.186.106 () {40 vars in 618 bytes} [Sun Jan 10 18:55:39 2021] POST / => generated 232 bytes in 0 msecs (HTTP/1.1 404) 2 headers in 87 bytes (1 switches on core 0)
[pid: 2191|app: 0|req: 7/11] 31.129.177.68 () {32 vars in 451 bytes} [Sun Jan 10 19:50:23 2021] GET / => generated 232 bytes in 0 msecs (HTTP/1.1 404) 2 headers in 87 bytes (1 switches on core 0)
[pid: 2190|app: 0|req: 4/12] 13.234.76.105 () {40 vars in 524 bytes} [Sun Jan 10 20:06:20 2021] POST /imginfer => generated 232 bytes in 0 msecs (HTTP/1.1 404) 2 headers in 87 bytes (2 switches on core 0)
[pid: 2190|app: 0|req: 5/13] 13.234.76.105 () {40 vars in 524 bytes} [Sun Jan 10 20:06:22 2021] POST /imginfer => generated 232 bytes in 0 msecs (HTTP/1.1 404) 2 headers in 87 bytes (1 switches on core 0)
[pid: 2189|app: 0|req: 1/14] 13.234.76.105 () {40 vars in 524 bytes} [Sun Jan 10 20:06:25 2021] POST /imginfer => generated 232 bytes in 2 msecs (HTTP/1.1 404) 2 headers in 87 bytes (1 switches on core 0)
[pid: 2188|app: 0|req: 1/15] 13.234.76.105 () {40 vars in 524 bytes} [Sun Jan 10 20:06:27 2021] POST /imginfer => generated 232 bytes in 2 msecs (HTTP/1.1 404) 2 headers in 87 bytes (1 switches on core 0)
SIGINT/SIGQUIT received...killing workers...
worker 1 buried after 1 seconds
worker 2 buried after 1 seconds
worker 3 buried after 1 seconds
worker 4 buried after 1 seconds
worker 5 buried after 1 seconds
goodbye to uWSGI.
VACUUM: unix socket enigma.sock removed.
*** Starting uWSGI 2.0.19.1 (64bit) on [Sun Jan 10 20:07:51 2021] ***
compiled with version: 9.3.0 on 10 January 2021 08:34:57
os: Linux-5.4.0-1029-aws #30-Ubuntu SMP Tue Oct 20 10:06:38 UTC 2020
nodename: ip-172-31-29-101
machine: x86_64
clock source: unix
detected number of CPU cores: 2
current working directory: /home/ubuntu/enigma
detected binary path: /home/ubuntu/venv/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
your processes number limit is 31409
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to UNIX address enigma.sock fd 3
Python version: 3.8.5 (default, Jul 28 2020, 12:59:40)  [GCC 9.3.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x562179afcbc0
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 437520 bytes (427 KB) for 5 cores
*** Operational MODE: preforking ***
WSGI app 0 (mountpoint='') ready in 4 seconds on interpreter 0x562179afcbc0 pid: 444 (default app)
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI master process (pid: 444)
spawned uWSGI worker 1 (pid: 711, cores: 1)
spawned uWSGI worker 2 (pid: 712, cores: 1)
spawned uWSGI worker 3 (pid: 713, cores: 1)
spawned uWSGI worker 4 (pid: 714, cores: 1)
spawned uWSGI worker 5 (pid: 715, cores: 1)
<_io.BytesIO object at 0x7f44dedd1040>
1
rohit488
{'State': 'MODEL_READY', 'prediction': 'Dog'}
[pid: 711|app: 0|req: 1/1] 13.234.76.105 () {40 vars in 522 bytes} [Sun Jan 10 20:08:01 2021] POST /imginfer => generated 43 bytes in 1255 msecs (HTTP/1.1 200) 2 headers in 71 bytes (1 switches on core 0)
[pid: 711|app: 0|req: 2/2] 157.55.39.41 () {40 vars in 541 bytes} [Sun Jan 10 20:10:21 2021] GET /robots.txt => generated 232 bytes in 1 msecs (HTTP/1.1 404) 2 headers in 87 bytes (1 switches on core 0)
<_io.BytesIO object at 0x7f44dedd1040>
1
rohit488
{'State': 'MODEL_READY', 'prediction': 'Tiger'}
[pid: 712|app: 0|req: 1/3] 13.235.54.203 () {40 vars in 524 bytes} [Sun Jan 10 20:15:09 2021] POST /imginfer => generated 45 bytes in 926 msecs (HTTP/1.1 200) 2 headers in 71 bytes (1 switches on core 0)
<_io.BytesIO object at 0x7f44de28bc20>
1
rohit488
{'State': 'MODEL_READY', 'prediction': 'Tiger'}
[pid: 711|app: 0|req: 3/4] 13.233.68.19 () {40 vars in 523 bytes} [Sun Jan 10 20:15:05 2021] POST /imginfer => generated 45 bytes in 5689 msecs (HTTP/1.1 200) 2 headers in 71 bytes (1 switches on core 0)
[pid: 715|app: 0|req: 1/5] 209.17.96.194 () {30 vars in 387 bytes} [Sun Jan 10 20:16:48 2021] GET / => generated 232 bytes in 3 msecs (HTTP/1.0 404) 2 headers in 87 bytes (1 switches on core 0)
[pid: 712|app: 0|req: 2/6] 139.162.119.197 () {32 vars in 388 bytes} [Sun Jan 10 20:36:12 2021] GET / => generated 232 bytes in 0 msecs (HTTP/1.1 404) 2 headers in 87 bytes (1 switches on core 0)
[pid: 714|app: 0|req: 1/7] 170.39.186.106 () {36 vars in 511 bytes} [Sun Jan 10 20:40:35 2021] GET /.env => generated 232 bytes in 3 msecs (HTTP/1.1 404) 2 headers in 87 bytes (1 switches on core 0)
[pid: 713|app: 0|req: 1/8] 170.39.186.106 () {40 vars in 618 bytes} [Sun Jan 10 20:40:35 2021] POST / => generated 232 bytes in 3 msecs (HTTP/1.1 404) 2 headers in 87 bytes (1 switches on core 0)
[pid: 712|app: 0|req: 3/9] 205.169.39.42 () {44 vars in 781 bytes} [Sun Jan 10 21:14:25 2021] GET / => generated 232 bytes in 0 msecs (HTTP/1.1 404) 2 headers in 87 bytes (2 switches on core 0)
[pid: 712|app: 0|req: 4/10] 205.169.39.133 () {48 vars in 850 bytes} [Sun Jan 10 21:16:19 2021] GET / => generated 232 bytes in 0 msecs (HTTP/1.1 404) 2 headers in 87 bytes (2 switches on core 0)
[pid: 712|app: 0|req: 5/11] 205.169.39.12 () {44 vars in 781 bytes} [Sun Jan 10 21:17:24 2021] GET / => generated 232 bytes in 0 msecs (HTTP/1.1 404) 2 headers in 87 bytes (1 switches on core 0)
[pid: 715|app: 0|req: 2/13] 185.220.101.16 () {32 vars in 392 bytes} [Sun Jan 10 21:17:28 2021] GET / => generated 232 bytes in 0 msecs (HTTP/1.1 404) 2 headers in 87 bytes (1 switches on core 0)
[pid: 712|app: 0|req: 6/13] 185.220.101.16 () {32 vars in 414 bytes} [Sun Jan 10 21:17:28 2021] GET /.git/config => generated 232 bytes in 0 msecs (HTTP/1.1 404) 2 headers in 87 bytes (1 switches on core 0)
[pid: 715|app: 0|req: 3/14] 185.220.101.16 () {32 vars in 414 bytes} [Sun Jan 10 21:17:28 2021] GET /v2/_catalog => generated 232 bytes in 0 msecs (HTTP/1.1 404) 2 headers in 87 bytes (1 switches on core 0)
[pid: 712|app: 0|req: 7/15] 185.220.101.16 () {32 vars in 400 bytes} [Sun Jan 10 21:17:29 2021] GET /.env => generated 232 bytes in 0 msecs (HTTP/1.1 404) 2 headers in 87 bytes (1 switches on core 0)
[pid: 712|app: 0|req: 8/16] 205.169.39.85 () {48 vars in 849 bytes} [Sun Jan 10 21:19:08 2021] GET / => generated 232 bytes in 0 msecs (HTTP/1.1 404) 2 headers in 87 bytes (1 switches on core 0)
SIGINT/SIGQUIT received...killing workers...
worker 1 buried after 1 seconds
worker 2 buried after 1 seconds
worker 3 buried after 1 seconds
worker 4 buried after 1 seconds
worker 5 buried after 1 seconds
goodbye to uWSGI.
VACUUM: unix socket enigma.sock removed.
*** Starting uWSGI 2.0.19.1 (64bit) on [Sun Jan 10 21:25:28 2021] ***
compiled with version: 9.3.0 on 10 January 2021 08:34:57
os: Linux-5.4.0-1029-aws #30-Ubuntu SMP Tue Oct 20 10:06:38 UTC 2020
nodename: ip-172-31-29-101
machine: x86_64
clock source: unix
detected number of CPU cores: 2
current working directory: /home/ubuntu/enigma
detected binary path: /home/ubuntu/venv/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
your processes number limit is 31409
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to UNIX address enigma.sock fd 3
Python version: 3.8.5 (default, Jul 28 2020, 12:59:40)  [GCC 9.3.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x55f88faeebc0
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 437520 bytes (427 KB) for 5 cores
*** Operational MODE: preforking ***
WSGI app 0 (mountpoint='') ready in 3 seconds on interpreter 0x55f88faeebc0 pid: 457 (default app)
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI master process (pid: 457)
spawned uWSGI worker 1 (pid: 726, cores: 1)
spawned uWSGI worker 2 (pid: 727, cores: 1)
spawned uWSGI worker 3 (pid: 728, cores: 1)
spawned uWSGI worker 4 (pid: 729, cores: 1)
spawned uWSGI worker 5 (pid: 730, cores: 1)
[pid: 730|app: 0|req: 1/1] 157.45.134.15 () {46 vars in 774 bytes} [Sun Jan 10 21:29:00 2021] OPTIONS /imgrecog => generated 0 bytes in 3 msecs (HTTP/1.1 200) 7 headers in 298 bytes (0 switches on core 0)
{'Project': 'IMG_REC', 'TOKEN_ID': 'rohit488', 'Ratio': '80', 'Epochs': '10'}
{'State': 'GEN_TOKEN', 'Name': 'rohit', 'Project': 'IMG_REC', 'TOKEN_ID': 'rohit488'}
[pid: 730|app: 0|req: 2/2] 157.45.134.15 () {46 vars in 740 bytes} [Sun Jan 10 21:29:01 2021] POST /imgrecog => generated 16 bytes in 1498 msecs (HTTP/1.1 200) 4 headers in 120 bytes (1 switches on core 0)
[pid: 730|app: 0|req: 3/3] 157.45.134.15 () {54 vars in 958 bytes} [Sun Jan 10 21:47:34 2021] OPTIONS /imgrecog => generated 0 bytes in 1 msecs (HTTP/1.1 200) 7 headers in 336 bytes (1 switches on core 0)
[pid: 727|app: 0|req: 1/4] 157.45.134.15 () {54 vars in 958 bytes} [Sun Jan 10 21:47:34 2021] OPTIONS /imgrecog => generated 0 bytes in 3 msecs (HTTP/1.1 200) 7 headers in 336 bytes (1 switches on core 0)
{'Project': 'IMG_REC', 'TOKEN_ID': 'rohit488', 'Ratio': '80', 'Epochs': '10'}
{'State': 'GEN_TOKEN', 'Name': 'rohit', 'Project': 'IMG_REC', 'TOKEN_ID': 'rohit488'}
[pid: 726|app: 0|req: 1/5] 157.45.134.15 () {60 vars in 1060 bytes} [Sun Jan 10 21:47:34 2021] POST /imgrecog => generated 16 bytes in 1148 msecs (HTTP/1.1 200) 4 headers in 158 bytes (1 switches on core 0)
{'Project': 'IMG_REC', 'TOKEN_ID': 'rohit488', 'Ratio': '80', 'Epochs': '10'}
{'State': 'GEN_TOKEN', 'Name': 'rohit', 'Project': 'IMG_REC', 'TOKEN_ID': 'rohit488'}
[pid: 729|app: 0|req: 1/6] 157.45.134.15 () {60 vars in 1060 bytes} [Sun Jan 10 21:47:34 2021] POST /imgrecog => generated 16 bytes in 1162 msecs (HTTP/1.1 200) 4 headers in 158 bytes (1 switches on core 0)
/home/ubuntu/venv/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
Using cache found in /home/ubuntu/.cache/torch/hub/pytorch_vision_v0.6.0
<_io.BytesIO object at 0x7f53381e32c0>
{'State': 'Error', 'Msg': 'Still training in progress!'}
[pid: 730|app: 0|req: 4/7] 35.154.54.99 () {42 vars in 565 bytes} [Sun Jan 10 21:52:58 2021] POST /imginfer => generated 54 bytes in 238 msecs (HTTP/1.1 200) 2 headers in 71 bytes (1 switches on core 0)
/home/ubuntu/venv/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
Using cache found in /home/ubuntu/.cache/torch/hub/pytorch_vision_v0.6.0
<_io.BytesIO object at 0x7f53382edc20>
{'State': 'Error', 'Msg': 'Still training in progress!'}
[pid: 729|app: 0|req: 2/8] 35.154.54.99 () {42 vars in 565 bytes} [Sun Jan 10 21:53:34 2021] POST /imginfer => generated 54 bytes in 188 msecs (HTTP/1.1 200) 2 headers in 71 bytes (1 switches on core 0)
<_io.BytesIO object at 0x7f53381e30e0>
{'State': 'Error', 'Msg': 'Still training in progress!'}
[pid: 730|app: 0|req: 5/9] 35.154.54.99 () {42 vars in 565 bytes} [Sun Jan 10 21:53:37 2021] POST /imginfer => generated 54 bytes in 238 msecs (HTTP/1.1 200) 2 headers in 71 bytes (1 switches on core 0)
SIGINT/SIGQUIT received...killing workers...
worker 1 buried after 1 seconds
worker 2 buried after 1 seconds
worker 3 buried after 1 seconds
worker 4 buried after 1 seconds
worker 5 buried after 1 seconds
goodbye to uWSGI.
VACUUM: unix socket enigma.sock removed.
*** Starting uWSGI 2.0.19.1 (64bit) on [Sun Jan 10 22:00:09 2021] ***
compiled with version: 9.3.0 on 10 January 2021 08:34:57
os: Linux-5.4.0-1029-aws #30-Ubuntu SMP Tue Oct 20 10:06:38 UTC 2020
nodename: ip-172-31-29-101
machine: x86_64
clock source: unix
detected number of CPU cores: 2
current working directory: /home/ubuntu/enigma
detected binary path: /home/ubuntu/venv/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
your processes number limit is 31409
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to UNIX address enigma.sock fd 3
Python version: 3.8.5 (default, Jul 28 2020, 12:59:40)  [GCC 9.3.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x5627ea04fbc0
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 437520 bytes (427 KB) for 5 cores
*** Operational MODE: preforking ***
WSGI app 0 (mountpoint='') ready in 3 seconds on interpreter 0x5627ea04fbc0 pid: 458 (default app)
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI master process (pid: 458)
spawned uWSGI worker 1 (pid: 727, cores: 1)
spawned uWSGI worker 2 (pid: 728, cores: 1)
spawned uWSGI worker 3 (pid: 729, cores: 1)
spawned uWSGI worker 4 (pid: 730, cores: 1)
spawned uWSGI worker 5 (pid: 731, cores: 1)
[pid: 730|app: 0|req: 1/1] 157.45.134.15 () {52 vars in 861 bytes} [Sun Jan 10 22:03:30 2021] OPTIONS /imgrecog => generated 0 bytes in 4 msecs (HTTP/1.1 200) 7 headers in 298 bytes (1 switches on core 0)
{'Project': 'IMG_REC', 'TOKEN_ID': 'gopika633', 'Ratio': '80', 'Epochs': '10'}
{'State': 'GEN_TOKEN', 'Name': 'Gopika', 'Project': 'IMG_REC', 'TOKEN_ID': 'gopika633'}
[pid: 727|app: 0|req: 1/2] 157.45.134.15 () {58 vars in 963 bytes} [Sun Jan 10 22:03:30 2021] POST /imgrecog => generated 16 bytes in 1201 msecs (HTTP/1.1 200) 4 headers in 120 bytes (1 switches on core 0)
<_io.BytesIO object at 0x7f0394bb03b0>
1
gopika633
{'State': 'MODEL_READY', 'prediction': 'gopika'}
[pid: 731|app: 0|req: 1/3] 13.232.245.233 () {42 vars in 567 bytes} [Sun Jan 10 22:14:16 2021] POST /imginfer => generated 46 bytes in 863 msecs (HTTP/1.1 200) 2 headers in 71 bytes (1 switches on core 0)
<_io.BytesIO object at 0x7f0394064b30>
1
gopika633
{'State': 'MODEL_READY', 'prediction': 'gopika'}
[pid: 731|app: 0|req: 2/4] 13.232.245.233 () {42 vars in 567 bytes} [Sun Jan 10 22:14:32 2021] POST /imginfer => generated 46 bytes in 808 msecs (HTTP/1.1 200) 2 headers in 71 bytes (1 switches on core 0)
[pid: 731|app: 0|req: 3/5] 157.45.134.15 () {54 vars in 958 bytes} [Sun Jan 10 22:20:08 2021] OPTIONS /imgrecog => generated 0 bytes in 1 msecs (HTTP/1.1 200) 7 headers in 336 bytes (0 switches on core 0)
{'Project': 'IMG_REC', 'TOKEN_ID': 'csr702', 'Ratio': '80', 'Epochs': '10'}
{'State': 'GEN_TOKEN', 'Name': 'csr', 'Project': 'IMG_REC', 'TOKEN_ID': 'csr702'}
[pid: 730|app: 0|req: 2/6] 157.45.134.15 () {60 vars in 1060 bytes} [Sun Jan 10 22:20:08 2021] POST /imgrecog => generated 16 bytes in 861 msecs (HTTP/1.1 200) 4 headers in 158 bytes (1 switches on core 0)
[pid: 731|app: 0|req: 4/7] 209.17.97.90 () {32 vars in 430 bytes} [Sun Jan 10 22:24:39 2021] GET / => generated 232 bytes in 0 msecs (HTTP/1.1 404) 2 headers in 87 bytes (2 switches on core 0)
*** Starting uWSGI 2.0.19.1 (64bit) on [Sun Jan 10 22:33:10 2021] ***
compiled with version: 9.3.0 on 10 January 2021 08:34:57
os: Linux-5.4.0-1029-aws #30-Ubuntu SMP Tue Oct 20 10:06:38 UTC 2020
nodename: ip-172-31-29-101
machine: x86_64
clock source: unix
detected number of CPU cores: 2
current working directory: /home/ubuntu/enigma
detected binary path: /home/ubuntu/venv/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
your processes number limit is 31409
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address 0.0.0.0:5000 fd 3
uwsgi socket 1 bound to UNIX address enigma.sock fd 4
Python version: 3.8.5 (default, Jul 28 2020, 12:59:40)  [GCC 9.3.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x55ac06fd7da0
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 437520 bytes (427 KB) for 5 cores
*** Operational MODE: preforking ***
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI master process (pid: 1414)
spawned uWSGI worker 1 (pid: 1415, cores: 1)
spawned uWSGI worker 2 (pid: 1416, cores: 1)
spawned uWSGI worker 3 (pid: 1417, cores: 1)
spawned uWSGI worker 4 (pid: 1418, cores: 1)
spawned uWSGI worker 5 (pid: 1419, cores: 1)
WSGI app 0 (mountpoint='') ready in 3 seconds on interpreter 0x55ac06fd7da0 pid: 1416 (default app)
WSGI app 0 (mountpoint='') ready in 3 seconds on interpreter 0x55ac06fd7da0 pid: 1417 (default app)
WSGI app 0 (mountpoint='') ready in 3 seconds on interpreter 0x55ac06fd7da0 pid: 1419 (default app)
WSGI app 0 (mountpoint='') ready in 3 seconds on interpreter 0x55ac06fd7da0 pid: 1415 (default app)
WSGI app 0 (mountpoint='') ready in 3 seconds on interpreter 0x55ac06fd7da0 pid: 1418 (default app)
SIGINT/SIGQUIT received...killing workers...
!!! uWSGI process 1419 got Segmentation Fault !!!
malloc(): unsorted double linked list corrupted
!!! uWSGI process 1416 got Segmentation Fault !!!
malloc(): unsorted double linked list corrupted
!!! uWSGI process 1417 got Segmentation Fault !!!
malloc(): unsorted double linked list corrupted
!!! uWSGI process 1415 got Segmentation Fault !!!
corrupted double-linked list
!!! uWSGI process 1418 got Segmentation Fault !!!
*** backtrace of 1418 ***
uwsgi(uwsgi_backtrace+0x2e) [0x55ac0636bdbe]
uwsgi(uwsgi_segfault+0x27) [0x55ac0636c1a7]
/lib/x86_64-linux-gnu/libc.so.6(+0x46210) [0x7f3823772210]
/lib/x86_64-linux-gnu/libc.so.6(+0x499f6) [0x7f38237759f6]
/lib/x86_64-linux-gnu/libc.so.6(on_exit+0) [0x7f3823775be0]
uwsgi(+0x3f455) [0x55ac0631f455]
uwsgi(end_me+0x2b) [0x55ac06368cdb]
/lib/x86_64-linux-gnu/libpthread.so.0(+0x153c0) [0x7f38243933c0]
/lib/x86_64-linux-gnu/libc.so.6(epoll_wait+0x5e) [0x7f382384e5ce]
uwsgi(event_queue_wait+0x39) [0x55ac0635ed99]
uwsgi(wsgi_req_accept+0x11a) [0x55ac0631c95a]
uwsgi(simple_loop_run+0xb6) [0x55ac06367be6]
uwsgi(simple_loop+0x14) [0x55ac063679d4]
uwsgi(uwsgi_ignition+0x2a4) [0x55ac0636c504]
uwsgi(uwsgi_worker_run+0x276) [0x55ac06370bc6]
uwsgi(uwsgi_run+0x454) [0x55ac06371144]
uwsgi(+0x3bd84) [0x55ac0631bd84]
/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf3) [0x7f38237530b3]
uwsgi(_start+0x2e) [0x55ac0631bdbe]
*** end of backtrace ***
worker 2 buried after 1 seconds
worker 3 buried after 1 seconds
worker 4 buried after 1 seconds
worker 5 buried after 1 seconds
worker 1 buried after 2 seconds
goodbye to uWSGI.
VACUUM: unix socket enigma.sock removed.
*** Starting uWSGI 2.0.19.1 (64bit) on [Sun Jan 10 22:37:24 2021] ***
compiled with version: 9.3.0 on 10 January 2021 08:34:57
os: Linux-5.4.0-1029-aws #30-Ubuntu SMP Tue Oct 20 10:06:38 UTC 2020
nodename: ip-172-31-29-101
machine: x86_64
clock source: unix
detected number of CPU cores: 2
current working directory: /home/ubuntu/enigma
detected binary path: /home/ubuntu/venv/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
your processes number limit is 31409
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to TCP address 0.0.0.0:5000 fd 3
uwsgi socket 1 bound to UNIX address enigma.sock fd 4
Python version: 3.8.5 (default, Jul 28 2020, 12:59:40)  [GCC 9.3.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x55fc05f89da0
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 437520 bytes (427 KB) for 5 cores
*** Operational MODE: preforking ***
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI master process (pid: 1439)
spawned uWSGI worker 1 (pid: 1440, cores: 1)
spawned uWSGI worker 2 (pid: 1441, cores: 1)
spawned uWSGI worker 3 (pid: 1442, cores: 1)
spawned uWSGI worker 4 (pid: 1443, cores: 1)
spawned uWSGI worker 5 (pid: 1444, cores: 1)
WSGI app 0 (mountpoint='') ready in 3 seconds on interpreter 0x55fc05f89da0 pid: 1440 (default app)
WSGI app 0 (mountpoint='') ready in 3 seconds on interpreter 0x55fc05f89da0 pid: 1443 (default app)
WSGI app 0 (mountpoint='') ready in 3 seconds on interpreter 0x55fc05f89da0 pid: 1442 (default app)
WSGI app 0 (mountpoint='') ready in 3 seconds on interpreter 0x55fc05f89da0 pid: 1444 (default app)
WSGI app 0 (mountpoint='') ready in 3 seconds on interpreter 0x55fc05f89da0 pid: 1441 (default app)
!!! uWSGI process 1443 got Segmentation Fault !!!
*** backtrace of 1443 ***
uwsgi(uwsgi_backtrace+0x2e) [0x55fc05b4edbe]
uwsgi(uwsgi_segfault+0x27) [0x55fc05b4f1a7]
/lib/x86_64-linux-gnu/libc.so.6(+0x46210) [0x7f4f318b1210]
/lib/x86_64-linux-gnu/libssl.so.1.1(SSL_get_rbio+0x4) [0x7f4f322f10f4]
/lib/x86_64-linux-gnu/libssl.so.1.1(SSL_set_bio+0x1c) [0x7f4f322f113c]
/lib/x86_64-linux-gnu/libssl.so.1.1(SSL_set_fd+0x48) [0x7f4f322f1328]
uwsgi(uwsgi_proto_ssl_accept+0x5e) [0x55fc05b5511e]
uwsgi(wsgi_req_accept+0x1e5) [0x55fc05affa25]
uwsgi(simple_loop_run+0xb6) [0x55fc05b4abe6]
uwsgi(simple_loop+0x14) [0x55fc05b4a9d4]
uwsgi(uwsgi_ignition+0x2a4) [0x55fc05b4f504]
uwsgi(uwsgi_worker_run+0x276) [0x55fc05b53bc6]
uwsgi(uwsgi_run+0x454) [0x55fc05b54144]
uwsgi(+0x3bd84) [0x55fc05afed84]
/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf3) [0x7f4f318920b3]
uwsgi(_start+0x2e) [0x55fc05afedbe]
*** end of backtrace ***
DAMN ! worker 4 (pid: 1443) died, killed by signal 11 :( trying respawn ...
Respawned uWSGI worker 4 (new pid: 1457)
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x55fc05f89da0 pid: 1457 (default app)
SIGINT/SIGQUIT received...killing workers...
!!! uWSGI process 1440 got Segmentation Fault !!!
corrupted double-linked list
!!! uWSGI process 1444 got Segmentation Fault !!!
corrupted double-linked list
!!! uWSGI process 1441 got Segmentation Fault !!!
*** backtrace of 1441 ***
uwsgi(uwsgi_backtrace+0x2e) [0x55fc05b4edbe]
uwsgi(uwsgi_segfault+0x27) [0x55fc05b4f1a7]
/lib/x86_64-linux-gnu/libc.so.6(+0x46210) [0x7f4f318b1210]
/lib/x86_64-linux-gnu/libc.so.6(+0x499f6) [0x7f4f318b49f6]
/lib/x86_64-linux-gnu/libc.so.6(on_exit+0) [0x7f4f318b4be0]
uwsgi(+0x3f455) [0x55fc05b02455]
uwsgi(end_me+0x2b) [0x55fc05b4bcdb]
/lib/x86_64-linux-gnu/libpthread.so.0(+0x153c0) [0x7f4f324d23c0]
/lib/x86_64-linux-gnu/libc.so.6(epoll_wait+0x5e) [0x7f4f3198d5ce]
uwsgi(event_queue_wait+0x39) [0x55fc05b41d99]
uwsgi(wsgi_req_accept+0x11a) [0x55fc05aff95a]
uwsgi(simple_loop_run+0xb6) [0x55fc05b4abe6]
uwsgi(simple_loop+0x14) [0x55fc05b4a9d4]
uwsgi(uwsgi_ignition+0x2a4) [0x55fc05b4f504]
uwsgi(uwsgi_worker_run+0x276) [0x55fc05b53bc6]
uwsgi(uwsgi_run+0x454) [0x55fc05b54144]
uwsgi(+0x3bd84) [0x55fc05afed84]
/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf3) [0x7f4f318920b3]
uwsgi(_start+0x2e) [0x55fc05afedbe]
*** end of backtrace ***
!!! uWSGI process 1442 got Segmentation Fault !!!
*** backtrace of 1442 ***
uwsgi(uwsgi_backtrace+0x2e) [0x55fc05b4edbe]
uwsgi(uwsgi_segfault+0x27) [0x55fc05b4f1a7]
/lib/x86_64-linux-gnu/libc.so.6(+0x46210) [0x7f4f318b1210]
/lib/x86_64-linux-gnu/libc.so.6(+0x499f6) [0x7f4f318b49f6]
/lib/x86_64-linux-gnu/libc.so.6(on_exit+0) [0x7f4f318b4be0]
uwsgi(+0x3f455) [0x55fc05b02455]
uwsgi(end_me+0x2b) [0x55fc05b4bcdb]
/lib/x86_64-linux-gnu/libpthread.so.0(+0x153c0) [0x7f4f324d23c0]
/lib/x86_64-linux-gnu/libpthread.so.0(pthread_cond_wait+0x216) [0x7f4f324cd376]
/home/ubuntu/venv/lib/python3.8/site-packages/numpy/core/../../numpy.libs/libopenblasp-r0-09e95953.3.13.so(+0x323f8b) [0x7f4eddcfbf8b]
/lib/x86_64-linux-gnu/libpthread.so.0(+0x9609) [0x7f4f324c6609]
/lib/x86_64-linux-gnu/libc.so.6(clone+0x43) [0x7f4f3198d293]
*** end of backtrace ***
!!! uWSGI process 1457 got Segmentation Fault !!!
*** backtrace of 1457 ***
uwsgi(uwsgi_backtrace+0x2e) [0x55fc05b4edbe]
uwsgi(uwsgi_segfault+0x27) [0x55fc05b4f1a7]
/lib/x86_64-linux-gnu/libc.so.6(+0x46210) [0x7f4f318b1210]
[0x55fc05f867f0]
*** end of backtrace ***
worker 1 buried after 1 seconds
worker 2 buried after 1 seconds
worker 3 buried after 1 seconds
worker 5 buried after 1 seconds
worker 4 buried after 1 seconds
goodbye to uWSGI.
VACUUM: unix socket enigma.sock removed.
SIGINT/SIGQUIT received...killing workers...
worker 1 buried after 1 seconds
worker 2 buried after 1 seconds
worker 3 buried after 1 seconds
worker 4 buried after 1 seconds
worker 5 buried after 1 seconds
goodbye to uWSGI.
unlink(): No such file or directory [core/uwsgi.c line 1662]
*** Starting uWSGI 2.0.19.1 (64bit) on [Sun Jan 10 22:40:35 2021] ***
compiled with version: 9.3.0 on 10 January 2021 08:34:57
os: Linux-5.4.0-1029-aws #30-Ubuntu SMP Tue Oct 20 10:06:38 UTC 2020
nodename: ip-172-31-29-101
machine: x86_64
clock source: unix
detected number of CPU cores: 2
current working directory: /home/ubuntu/enigma
detected binary path: /home/ubuntu/venv/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
your processes number limit is 31409
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to UNIX address enigma.sock fd 3
Python version: 3.8.5 (default, Jul 28 2020, 12:59:40)  [GCC 9.3.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x55a135e58bc0
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 437520 bytes (427 KB) for 5 cores
*** Operational MODE: preforking ***
WSGI app 0 (mountpoint='') ready in 3 seconds on interpreter 0x55a135e58bc0 pid: 457 (default app)
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI master process (pid: 457)
spawned uWSGI worker 1 (pid: 726, cores: 1)
spawned uWSGI worker 2 (pid: 727, cores: 1)
spawned uWSGI worker 3 (pid: 728, cores: 1)
spawned uWSGI worker 4 (pid: 729, cores: 1)
[pid: 726|app: 0|req: 1/1] 157.45.134.15 () {54 vars in 958 bytes} [Sun Jan 10 22:40:39 2021] OPTIONS /imgrecog => generated 0 bytes in 4 msecs (HTTP/1.1 200) 7 headers in 336 bytes (0 switches on core 0)
[pid: 726|app: 0|req: 2/2] 157.45.134.15 () {54 vars in 958 bytes} [Sun Jan 10 22:40:39 2021] OPTIONS /imgrecog => generated 0 bytes in 0 msecs (HTTP/1.1 200) 7 headers in 336 bytes (0 switches on core 0)
spawned uWSGI worker 5 (pid: 730, cores: 1)
{'Project': 'IMG_REC', 'TOKEN_ID': 'csr468', 'Ratio': '80', 'Epochs': '10'}
{'State': 'GEN_TOKEN', 'Name': 'CSR', 'Project': 'IMG_REC', 'TOKEN_ID': 'csr468'}
[pid: 726|app: 0|req: 3/3] 157.45.134.15 () {60 vars in 1060 bytes} [Sun Jan 10 22:40:40 2021] POST /imgrecog => generated 16 bytes in 1156 msecs (HTTP/1.1 200) 4 headers in 158 bytes (1 switches on core 0)
{'Project': 'IMG_REC', 'TOKEN_ID': 'csr468', 'Ratio': '80', 'Epochs': '10'}
{'State': 'GEN_TOKEN', 'Name': 'CSR', 'Project': 'IMG_REC', 'TOKEN_ID': 'csr468'}
[pid: 729|app: 0|req: 1/4] 157.45.134.15 () {60 vars in 1060 bytes} [Sun Jan 10 22:40:40 2021] POST /imgrecog => generated 16 bytes in 1159 msecs (HTTP/1.1 200) 4 headers in 158 bytes (1 switches on core 0)
[pid: 727|app: 0|req: 1/5] 54.221.27.173 () {38 vars in 572 bytes} [Sun Jan 10 22:46:22 2021] GET / => generated 232 bytes in 3 msecs (HTTP/1.1 404) 2 headers in 87 bytes (1 switches on core 0)
[pid: 727|app: 0|req: 2/6] 157.45.134.15 () {54 vars in 958 bytes} [Sun Jan 10 22:52:07 2021] OPTIONS /imgrecog => generated 0 bytes in 1 msecs (HTTP/1.1 200) 7 headers in 336 bytes (1 switches on core 0)
/home/ubuntu/venv/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
Using cache found in /home/ubuntu/.cache/torch/hub/pytorch_vision_v0.6.0
Epoch [0], last_lr: 0.0000, train_loss: 0.7489, val_loss: 0.7365, val_score: 0.3333
Epoch [1], last_lr: 0.0002, train_loss: 0.7562, val_loss: 0.7426, val_score: 0.3333
{'Project': 'IMG_REC', 'TOKEN_ID': 'csr468', 'Ratio': '80', 'Epochs': '10'}
{'State': 'GEN_TOKEN', 'Name': 'CSR', 'Project': 'IMG_REC', 'TOKEN_ID': 'csr468'}
[pid: 729|app: 0|req: 2/7] 157.45.134.15 () {60 vars in 1060 bytes} [Sun Jan 10 22:52:07 2021] POST /imgrecog => generated 16 bytes in 5747 msecs (HTTP/1.1 200) 4 headers in 158 bytes (1 switches on core 0)
[pid: 730|app: 0|req: 1/8] 157.45.134.15 () {54 vars in 958 bytes} [Sun Jan 10 22:58:04 2021] OPTIONS /imgrecog => generated 0 bytes in 3 msecs (HTTP/1.1 200) 7 headers in 336 bytes (0 switches on core 0)
{'Project': 'IMG_REC', 'TOKEN_ID': 'csr468', 'Ratio': '80', 'Epochs': '10'}
{'State': 'GEN_TOKEN', 'Name': 'CSR', 'Project': 'IMG_REC', 'TOKEN_ID': 'csr468'}
[pid: 727|app: 0|req: 3/9] 157.45.134.15 () {60 vars in 1060 bytes} [Sun Jan 10 22:58:04 2021] POST /imgrecog => generated 16 bytes in 662 msecs (HTTP/1.1 200) 4 headers in 158 bytes (1 switches on core 0)
SIGINT/SIGQUIT received...killing workers...
/home/ubuntu/venv/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
Exception in thread Thread-1:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "./imageRecognision.py", line 69, in imageRecognision
    device = get_default_device()
  File "./dataloader.py", line 39, in get_default_device
    return torch.device('cpu')
RuntimeError: FunctionParameter(): invalid type string: Device
/home/ubuntu/venv/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
Exception in thread Thread-1:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "./imageRecognision.py", line 69, in imageRecognision
    device = get_default_device()
  File "./dataloader.py", line 39, in get_default_device
    return torch.device('cpu')
RuntimeError: FunctionParameter(): invalid type string: Device
terminate called without an active exception
worker 1 buried after 1 seconds
worker 2 buried after 1 seconds
worker 3 buried after 1 seconds
worker 5 buried after 1 seconds
worker 4 buried after 2 seconds
goodbye to uWSGI.
VACUUM: unix socket enigma.sock removed.
*** Starting uWSGI 2.0.19.1 (64bit) on [Sun Jan 10 23:02:35 2021] ***
compiled with version: 9.3.0 on 10 January 2021 08:34:57
os: Linux-5.4.0-1029-aws #30-Ubuntu SMP Tue Oct 20 10:06:38 UTC 2020
nodename: ip-172-31-29-101
machine: x86_64
clock source: unix
detected number of CPU cores: 2
current working directory: /home/ubuntu/enigma
detected binary path: /home/ubuntu/venv/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
your processes number limit is 31409
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to UNIX address enigma.sock fd 3
Python version: 3.8.5 (default, Jul 28 2020, 12:59:40)  [GCC 9.3.0]
Python main interpreter initialized at 0x55c661d24cc0
python threads support enabled
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 437520 bytes (427 KB) for 5 cores
*** Operational MODE: preforking ***
WSGI app 0 (mountpoint='') ready in 3 seconds on interpreter 0x55c661d24cc0 pid: 457 (default app)
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI master process (pid: 457)
spawned uWSGI worker 1 (pid: 831, cores: 1)
spawned uWSGI worker 2 (pid: 832, cores: 1)
spawned uWSGI worker 3 (pid: 833, cores: 1)
spawned uWSGI worker 4 (pid: 834, cores: 1)
spawned uWSGI worker 5 (pid: 835, cores: 1)
SIGINT/SIGQUIT received...killing workers...
worker 1 buried after 1 seconds
worker 2 buried after 1 seconds
worker 3 buried after 1 seconds
worker 4 buried after 1 seconds
worker 5 buried after 1 seconds
goodbye to uWSGI.
VACUUM: unix socket enigma.sock removed.
*** Starting uWSGI 2.0.19.1 (64bit) on [Sun Jan 10 23:18:44 2021] ***
compiled with version: 9.3.0 on 10 January 2021 08:34:57
os: Linux-5.4.0-1029-aws #30-Ubuntu SMP Tue Oct 20 10:06:38 UTC 2020
nodename: ip-172-31-29-101
machine: x86_64
clock source: unix
detected number of CPU cores: 2
current working directory: /home/ubuntu/enigma
detected binary path: /home/ubuntu/venv/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
your processes number limit is 31409
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to UNIX address enigma.sock fd 3
Python version: 3.8.5 (default, Jul 28 2020, 12:59:40)  [GCC 9.3.0]
Python main interpreter initialized at 0x557a38a5ecc0
python threads support enabled
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 437520 bytes (427 KB) for 5 cores
*** Operational MODE: preforking ***
Traceback (most recent call last):
  File "./wsgi.py", line 1, in <module>
    from app import app
  File "./app.py", line 40
    args=(ID, epochs, Ratio, ), daemon=True)
                                           ^
SyntaxError: unmatched ')'
unable to load app 0 (mountpoint='') (callable not found or import error)
*** no app loaded. going in full dynamic mode ***
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI master process (pid: 457)
spawned uWSGI worker 1 (pid: 547, cores: 1)
spawned uWSGI worker 2 (pid: 548, cores: 1)
spawned uWSGI worker 3 (pid: 549, cores: 1)
spawned uWSGI worker 4 (pid: 550, cores: 1)
spawned uWSGI worker 5 (pid: 551, cores: 1)
SIGINT/SIGQUIT received...killing workers...
worker 1 buried after 0 seconds
worker 2 buried after 0 seconds
worker 3 buried after 0 seconds
worker 4 buried after 0 seconds
worker 5 buried after 0 seconds
goodbye to uWSGI.
VACUUM: unix socket enigma.sock removed.
*** Starting uWSGI 2.0.19.1 (64bit) on [Sun Jan 10 23:27:02 2021] ***
compiled with version: 9.3.0 on 10 January 2021 08:34:57
os: Linux-5.4.0-1029-aws #30-Ubuntu SMP Tue Oct 20 10:06:38 UTC 2020
nodename: ip-172-31-29-101
machine: x86_64
clock source: unix
detected number of CPU cores: 2
current working directory: /home/ubuntu/enigma
detected binary path: /home/ubuntu/venv/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
your processes number limit is 31409
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to UNIX address enigma.sock fd 3
Python version: 3.8.5 (default, Jul 28 2020, 12:59:40)  [GCC 9.3.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x559ff5858bc0
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 437520 bytes (427 KB) for 5 cores
*** Operational MODE: preforking ***
WSGI app 0 (mountpoint='') ready in 4 seconds on interpreter 0x559ff5858bc0 pid: 457 (default app)
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI master process (pid: 457)
spawned uWSGI worker 1 (pid: 823, cores: 1)
spawned uWSGI worker 2 (pid: 824, cores: 1)
spawned uWSGI worker 3 (pid: 825, cores: 1)
spawned uWSGI worker 4 (pid: 826, cores: 1)
spawned uWSGI worker 5 (pid: 827, cores: 1)
SIGINT/SIGQUIT received...killing workers...
worker 1 buried after 1 seconds
worker 2 buried after 1 seconds
worker 3 buried after 1 seconds
worker 4 buried after 1 seconds
worker 5 buried after 1 seconds
goodbye to uWSGI.
VACUUM: unix socket enigma.sock removed.
*** Starting uWSGI 2.0.19.1 (64bit) on [Sun Jan 10 23:50:56 2021] ***
compiled with version: 9.3.0 on 10 January 2021 08:34:57
os: Linux-5.4.0-1029-aws #30-Ubuntu SMP Tue Oct 20 10:06:38 UTC 2020
nodename: ip-172-31-29-101
machine: x86_64
clock source: unix
detected number of CPU cores: 2
current working directory: /home/ubuntu/enigma
detected binary path: /home/ubuntu/venv/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
your processes number limit is 31409
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to UNIX address enigma.sock fd 3
Python version: 3.8.5 (default, Jul 28 2020, 12:59:40)  [GCC 9.3.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x565119e94bc0
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 437520 bytes (427 KB) for 5 cores
*** Operational MODE: preforking ***
WSGI app 0 (mountpoint='') ready in 3 seconds on interpreter 0x565119e94bc0 pid: 457 (default app)
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI master process (pid: 457)
spawned uWSGI worker 1 (pid: 745, cores: 1)
spawned uWSGI worker 2 (pid: 747, cores: 1)
spawned uWSGI worker 3 (pid: 749, cores: 1)
spawned uWSGI worker 4 (pid: 750, cores: 1)
spawned uWSGI worker 5 (pid: 751, cores: 1)
SIGINT/SIGQUIT received...killing workers...
worker 1 buried after 1 seconds
worker 2 buried after 1 seconds
worker 3 buried after 1 seconds
worker 4 buried after 1 seconds
worker 5 buried after 1 seconds
goodbye to uWSGI.
VACUUM: unix socket enigma.sock removed.
*** Starting uWSGI 2.0.19.1 (64bit) on [Sun Jan 10 23:57:35 2021] ***
compiled with version: 9.3.0 on 10 January 2021 08:34:57
os: Linux-5.4.0-1029-aws #30-Ubuntu SMP Tue Oct 20 10:06:38 UTC 2020
nodename: ip-172-31-29-101
machine: x86_64
clock source: unix
detected number of CPU cores: 2
current working directory: /home/ubuntu/enigma
detected binary path: /home/ubuntu/venv/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
your processes number limit is 31409
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to UNIX address enigma.sock fd 3
Python version: 3.8.5 (default, Jul 28 2020, 12:59:40)  [GCC 9.3.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x55fc97693bc0
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 437520 bytes (427 KB) for 5 cores
*** Operational MODE: preforking ***
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x55fc97693bc0 pid: 963 (default app)
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI master process (pid: 963)
spawned uWSGI worker 1 (pid: 988, cores: 1)
spawned uWSGI worker 2 (pid: 989, cores: 1)
spawned uWSGI worker 3 (pid: 990, cores: 1)
spawned uWSGI worker 4 (pid: 991, cores: 1)
spawned uWSGI worker 5 (pid: 992, cores: 1)
SIGINT/SIGQUIT received...killing workers...
worker 1 buried after 1 seconds
worker 2 buried after 2 seconds
worker 3 buried after 2 seconds
worker 4 buried after 2 seconds
worker 5 buried after 2 seconds
goodbye to uWSGI.
VACUUM: unix socket enigma.sock removed.
*** Starting uWSGI 2.0.19.1 (64bit) on [Mon Jan 11 00:06:35 2021] ***
compiled with version: 9.3.0 on 10 January 2021 08:34:57
os: Linux-5.4.0-1029-aws #30-Ubuntu SMP Tue Oct 20 10:06:38 UTC 2020
nodename: ip-172-31-29-101
machine: x86_64
clock source: unix
detected number of CPU cores: 2
current working directory: /home/ubuntu/enigma
detected binary path: /home/ubuntu/venv/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
your processes number limit is 31409
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to UNIX address enigma.sock fd 3
Python version: 3.8.5 (default, Jul 28 2020, 12:59:40)  [GCC 9.3.0]
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x559e4cb5fbc0
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 437520 bytes (427 KB) for 5 cores
*** Operational MODE: preforking ***
WSGI app 0 (mountpoint='') ready in 4 seconds on interpreter 0x559e4cb5fbc0 pid: 457 (default app)
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI master process (pid: 457)
spawned uWSGI worker 1 (pid: 831, cores: 1)
spawned uWSGI worker 2 (pid: 832, cores: 1)
spawned uWSGI worker 3 (pid: 833, cores: 1)
spawned uWSGI worker 4 (pid: 834, cores: 1)
spawned uWSGI worker 5 (pid: 835, cores: 1)
SIGINT/SIGQUIT received...killing workers...
worker 1 buried after 1 seconds
worker 2 buried after 1 seconds
worker 5 buried after 1 seconds
worker 3 buried after 2 seconds
worker 4 buried after 2 seconds
goodbye to uWSGI.
VACUUM: unix socket enigma.sock removed.
*** Starting uWSGI 2.0.19.1 (64bit) on [Mon Jan 11 00:08:58 2021] ***
compiled with version: 9.3.0 on 10 January 2021 08:34:57
os: Linux-5.4.0-1029-aws #30-Ubuntu SMP Tue Oct 20 10:06:38 UTC 2020
nodename: ip-172-31-29-101
machine: x86_64
clock source: unix
detected number of CPU cores: 2
current working directory: /home/ubuntu/enigma
detected binary path: /home/ubuntu/venv/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
your processes number limit is 31409
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to UNIX address enigma.sock fd 3
Python version: 3.8.5 (default, Jul 28 2020, 12:59:40)  [GCC 9.3.0]
Python main interpreter initialized at 0x56523201dcc0
python threads support enabled
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 437520 bytes (427 KB) for 5 cores
*** Operational MODE: preforking ***
WSGI app 0 (mountpoint='') ready in 3 seconds on interpreter 0x56523201dcc0 pid: 456 (default app)
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI master process (pid: 456)
spawned uWSGI worker 1 (pid: 723, cores: 1)
spawned uWSGI worker 2 (pid: 724, cores: 1)
spawned uWSGI worker 3 (pid: 725, cores: 1)
spawned uWSGI worker 4 (pid: 726, cores: 1)
spawned uWSGI worker 5 (pid: 727, cores: 1)
[pid: 725|app: 0|req: 1/1] 157.45.134.15 () {54 vars in 952 bytes} [Mon Jan 11 00:15:22 2021] OPTIONS /hello => generated 0 bytes in 3 msecs (HTTP/1.1 200) 7 headers in 336 bytes (1 switches on core 0)
[pid: 727|app: 0|req: 1/2] 157.45.134.15 () {60 vars in 1054 bytes} [Mon Jan 11 00:15:22 2021] POST /hello => generated 16 bytes in 3 msecs (HTTP/1.1 200) 4 headers in 158 bytes (1 switches on core 0)
[pid: 727|app: 0|req: 2/3] 157.45.134.15 () {54 vars in 958 bytes} [Mon Jan 11 00:15:22 2021] OPTIONS /imgrecog => generated 0 bytes in 1 msecs (HTTP/1.1 200) 7 headers in 336 bytes (0 switches on core 0)
{'Project': 'IMG_REC', 'TOKEN_ID': 'csr468', 'Ratio': '80', 'Epochs': '10'}
<_io.BytesIO object at 0x7f1af26a0d60>
1
gopika633
<_io.BytesIO object at 0x7f1af25fe9a0>
1
gopika633
/home/ubuntu/venv/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
Using cache found in /home/ubuntu/.cache/torch/hub/pytorch_vision_v0.6.0
{'State': 'MODEL_READY', 'prediction': 'gopika'}
[pid: 725|app: 0|req: 2/4] 13.235.56.216 () {42 vars in 566 bytes} [Mon Jan 11 00:15:22 2021] POST /imginfer => generated 46 bytes in 1794 msecs (HTTP/1.1 200) 2 headers in 71 bytes (1 switches on core 0)
{'State': 'MODEL_READY', 'prediction': 'gopika'}
[pid: 724|app: 0|req: 1/5] 13.235.216.243 () {42 vars in 567 bytes} [Mon Jan 11 00:15:22 2021] POST /imginfer => generated 46 bytes in 1783 msecs (HTTP/1.1 200) 2 headers in 71 bytes (1 switches on core 0)
[pid: 726|app: 0|req: 1/6] 157.45.134.15 () {60 vars in 1054 bytes} [Mon Jan 11 00:15:25 2021] POST /hello => generated 16 bytes in 3 msecs (HTTP/1.1 200) 4 headers in 158 bytes (1 switches on core 0)
[pid: 725|app: 0|req: 3/7] 157.45.134.15 () {60 vars in 1054 bytes} [Mon Jan 11 00:15:25 2021] POST /hello => generated 16 bytes in 0 msecs (HTTP/1.1 200) 4 headers in 158 bytes (1 switches on core 0)
[pid: 725|app: 0|req: 4/8] 157.45.134.15 () {60 vars in 1054 bytes} [Mon Jan 11 00:15:25 2021] POST /hello => generated 16 bytes in 0 msecs (HTTP/1.1 200) 4 headers in 158 bytes (1 switches on core 0)
[pid: 726|app: 0|req: 2/9] 157.45.134.15 () {60 vars in 1054 bytes} [Mon Jan 11 00:15:25 2021] POST /hello => generated 16 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 158 bytes (1 switches on core 0)
[pid: 724|app: 0|req: 2/10] 157.45.134.15 () {60 vars in 1054 bytes} [Mon Jan 11 00:15:25 2021] POST /hello => generated 16 bytes in 1 msecs (HTTP/1.1 200) 4 headers in 158 bytes (1 switches on core 0)
[pid: 726|app: 0|req: 3/11] 157.45.134.15 () {60 vars in 1054 bytes} [Mon Jan 11 00:15:25 2021] POST /hello => generated 16 bytes in 0 msecs (HTTP/1.1 200) 4 headers in 158 bytes (1 switches on core 0)
{'Project': 'IMG_REC', 'TOKEN_ID': 'csr468', 'Ratio': '80', 'Epochs': '10'}
{'Project': 'IMG_REC', 'TOKEN_ID': 'csr468', 'Ratio': '80', 'Epochs': '10'}
{'Project': 'IMG_REC', 'TOKEN_ID': 'csr468', 'Ratio': '80', 'Epochs': '10'}
{'Project': 'IMG_REC', 'TOKEN_ID': 'csr468', 'Ratio': '80', 'Epochs': '10'}
/home/ubuntu/venv/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
Using cache found in /home/ubuntu/.cache/torch/hub/pytorch_vision_v0.6.0
/home/ubuntu/venv/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
Using cache found in /home/ubuntu/.cache/torch/hub/pytorch_vision_v0.6.0
/home/ubuntu/venv/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
Using cache found in /home/ubuntu/.cache/torch/hub/pytorch_vision_v0.6.0
/home/ubuntu/venv/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
Using cache found in /home/ubuntu/.cache/torch/hub/pytorch_vision_v0.6.0
Epoch [0], last_lr: 0.0000, train_loss: 0.7110, val_loss: 0.9033, val_score: 0.0000
Epoch [0], last_lr: 0.0000, train_loss: 0.7110, val_loss: 0.9033, val_score: 0.0000
Epoch [0], last_lr: 0.0000, train_loss: 0.7110, val_loss: 0.9033, val_score: 0.0000
Epoch [0], last_lr: 0.0000, train_loss: 0.7110, val_loss: 0.9033, val_score: 0.0000
Epoch [1], last_lr: 0.0002, train_loss: 0.7227, val_loss: 0.8926, val_score: 0.0000
Epoch [0], last_lr: 0.0000, train_loss: 0.7110, val_loss: 0.9033, val_score: 0.0000
Epoch [1], last_lr: 0.0002, train_loss: 0.7227, val_loss: 0.8926, val_score: 0.0000
Epoch [2], last_lr: 0.0004, train_loss: 0.6412, val_loss: 0.8909, val_score: 0.0000
Epoch [1], last_lr: 0.0002, train_loss: 0.7227, val_loss: 0.8926, val_score: 0.0000
Epoch [1], last_lr: 0.0002, train_loss: 0.7227, val_loss: 0.8926, val_score: 0.0000
Epoch [1], last_lr: 0.0002, train_loss: 0.7227, val_loss: 0.8926, val_score: 0.0000
Epoch [3], last_lr: 0.0006, train_loss: 0.7951, val_loss: 0.8720, val_score: 0.0000
Epoch [2], last_lr: 0.0004, train_loss: 0.6412, val_loss: 0.8909, val_score: 0.0000
Epoch [2], last_lr: 0.0004, train_loss: 0.6412, val_loss: 0.8909, val_score: 0.0000
Epoch [2], last_lr: 0.0004, train_loss: 0.6412, val_loss: 0.8909, val_score: 0.0000
Epoch [2], last_lr: 0.0004, train_loss: 0.6412, val_loss: 0.8909, val_score: 0.0000
Epoch [4], last_lr: 0.0008, train_loss: 0.6701, val_loss: 0.8521, val_score: 0.0000
Epoch [3], last_lr: 0.0006, train_loss: 0.7951, val_loss: 0.8720, val_score: 0.0000
Epoch [3], last_lr: 0.0006, train_loss: 0.7951, val_loss: 0.8720, val_score: 0.0000
Epoch [3], last_lr: 0.0006, train_loss: 0.7951, val_loss: 0.8720, val_score: 0.0000
Epoch [3], last_lr: 0.0006, train_loss: 0.7951, val_loss: 0.8720, val_score: 0.0000
Epoch [5], last_lr: 0.0010, train_loss: 0.7224, val_loss: 0.8506, val_score: 0.0000
Epoch [4], last_lr: 0.0008, train_loss: 0.6701, val_loss: 0.8521, val_score: 0.0000
Epoch [4], last_lr: 0.0008, train_loss: 0.6701, val_loss: 0.8521, val_score: 0.0000
Epoch [4], last_lr: 0.0008, train_loss: 0.6701, val_loss: 0.8521, val_score: 0.0000
Epoch [4], last_lr: 0.0008, train_loss: 0.6701, val_loss: 0.8521, val_score: 0.0000
Epoch [6], last_lr: 0.0012, train_loss: 0.7035, val_loss: 0.8108, val_score: 0.0000
Epoch [5], last_lr: 0.0010, train_loss: 0.7224, val_loss: 0.8506, val_score: 0.0000
Epoch [5], last_lr: 0.0010, train_loss: 0.7224, val_loss: 0.8506, val_score: 0.0000
Epoch [5], last_lr: 0.0010, train_loss: 0.7224, val_loss: 0.8506, val_score: 0.0000
Epoch [5], last_lr: 0.0010, train_loss: 0.7224, val_loss: 0.8506, val_score: 0.0000
Epoch [7], last_lr: 0.0014, train_loss: 0.6577, val_loss: 0.7958, val_score: 0.0000
Epoch [6], last_lr: 0.0012, train_loss: 0.7035, val_loss: 0.8108, val_score: 0.0000
Epoch [6], last_lr: 0.0012, train_loss: 0.7035, val_loss: 0.8108, val_score: 0.0000
Epoch [6], last_lr: 0.0012, train_loss: 0.7035, val_loss: 0.8108, val_score: 0.0000
Epoch [6], last_lr: 0.0012, train_loss: 0.7035, val_loss: 0.8108, val_score: 0.0000
Epoch [8], last_lr: 0.0016, train_loss: 0.7048, val_loss: 0.7796, val_score: 0.0000
Epoch [7], last_lr: 0.0014, train_loss: 0.6577, val_loss: 0.7958, val_score: 0.0000
Epoch [7], last_lr: 0.0014, train_loss: 0.6577, val_loss: 0.7958, val_score: 0.0000
Epoch [7], last_lr: 0.0014, train_loss: 0.6577, val_loss: 0.7958, val_score: 0.0000
Epoch [7], last_lr: 0.0014, train_loss: 0.6577, val_loss: 0.7958, val_score: 0.0000
Epoch [9], last_lr: 0.0018, train_loss: 0.6757, val_loss: 0.7794, val_score: 0.0000
best accuracy = 0.0
Epoch [8], last_lr: 0.0016, train_loss: 0.7048, val_loss: 0.7796, val_score: 0.0000
Epoch [8], last_lr: 0.0016, train_loss: 0.7048, val_loss: 0.7796, val_score: 0.0000
Epoch [8], last_lr: 0.0016, train_loss: 0.7048, val_loss: 0.7796, val_score: 0.0000
Epoch [8], last_lr: 0.0016, train_loss: 0.7048, val_loss: 0.7796, val_score: 0.0000
{'Project': 'IMG_REC', 'TOKEN_ID': 'csr468', 'Ratio': '80', 'Epochs': '10'}
{'State': 'GEN_TOKEN', 'Name': 'CSR', 'Project': 'IMG_REC', 'TOKEN_ID': 'csr468'}
Mon Jan 11 00:16:39 2021 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request /imgrecog (ip 157.45.134.15) !!!
Mon Jan 11 00:16:39 2021 - uwsgi_response_writev_headers_and_body_do(): Broken pipe [core/writer.c line 306] during POST /imgrecog (157.45.134.15)
OSError: write error
[pid: 727|app: 0|req: 3/12] 157.45.134.15 () {60 vars in 1060 bytes} [Mon Jan 11 00:15:22 2021] POST /imgrecog => generated 0 bytes in 76792 msecs (HTTP/1.1 200) 4 headers in 0 bytes (0 switches on core 0)
{'Project': 'IMG_REC', 'TOKEN_ID': 'csr468', 'Ratio': '80', 'Epochs': '10'}
[2021-01-11 00:16:39,376] ERROR in app: Exception on /imgrecog [POST]
Traceback (most recent call last):
  File "/home/ubuntu/venv/lib/python3.8/site-packages/flask/app.py", line 2447, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/ubuntu/venv/lib/python3.8/site-packages/flask/app.py", line 1952, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/ubuntu/venv/lib/python3.8/site-packages/flask_cors/extension.py", line 165, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "/home/ubuntu/venv/lib/python3.8/site-packages/flask_cors/extension.py", line 165, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "/home/ubuntu/venv/lib/python3.8/site-packages/flask/app.py", line 1821, in handle_user_exception
    reraise(exc_type, exc_value, tb)
  File "/home/ubuntu/venv/lib/python3.8/site-packages/flask/_compat.py", line 39, in reraise
    raise value
  File "/home/ubuntu/venv/lib/python3.8/site-packages/flask/app.py", line 1950, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/ubuntu/venv/lib/python3.8/site-packages/flask/app.py", line 1936, in dispatch_request
    return self.view_functions[rule.endpoint](**req.view_args)
  File "./app.py", line 45, in imgRecog
    imageRecognision(ID, epochs, Ratio)
  File "./imageRecognision.py", line 78, in imageRecognision
    history += fit_one_cycle(epochs, max_lr, model, train_dl, val_dl,
  File "./train.py", line 36, in fit_one_cycle
    for batch in train_loader:
  File "./dataloader.py", line 55, in __iter__
    for b in self.dl:
  File "/home/ubuntu/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 435, in __next__
    data = self._next_data()
  File "/home/ubuntu/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 475, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/ubuntu/venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ubuntu/venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ubuntu/venv/lib/python3.8/site-packages/torch/utils/data/dataset.py", line 272, in __getitem__
    return self.dataset[self.indices[idx]]
  File "/home/ubuntu/venv/lib/python3.8/site-packages/torchvision/datasets/folder.py", line 151, in __getitem__
    sample = self.loader(path)
  File "/home/ubuntu/venv/lib/python3.8/site-packages/torchvision/datasets/folder.py", line 188, in default_loader
    return pil_loader(path)
  File "/home/ubuntu/venv/lib/python3.8/site-packages/torchvision/datasets/folder.py", line 168, in pil_loader
    with open(path, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'csr468/dataset/CSR/4.jpg'
Mon Jan 11 00:16:39 2021 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request /imgrecog (ip 157.45.134.15) !!!
Mon Jan 11 00:16:39 2021 - uwsgi_response_writev_headers_and_body_do(): Broken pipe [core/writer.c line 306] during POST /imgrecog (157.45.134.15)
OSError: write error
[pid: 724|app: 0|req: 3/13] 157.45.134.15 () {60 vars in 1060 bytes} [Mon Jan 11 00:15:25 2021] POST /imgrecog => generated 0 bytes in 74109 msecs (HTTP/1.1 500) 4 headers in 0 bytes (0 switches on core 0)
{'Project': 'IMG_REC', 'TOKEN_ID': 'csr468', 'Ratio': '80', 'Epochs': '10'}
Using cache found in /home/ubuntu/.cache/torch/hub/pytorch_vision_v0.6.0
Using cache found in /home/ubuntu/.cache/torch/hub/pytorch_vision_v0.6.0
Epoch [9], last_lr: 0.0018, train_loss: 0.6757, val_loss: 0.7794, val_score: 0.0000
best accuracy = 0.0
Epoch [9], last_lr: 0.0018, train_loss: 0.6757, val_loss: 0.7794, val_score: 0.0000
best accuracy = 0.0
Epoch [9], last_lr: 0.0018, train_loss: 0.6757, val_loss: 0.7794, val_score: 0.0000
best accuracy = 0.0
{'Project': 'IMG_REC', 'TOKEN_ID': 'csr468', 'Ratio': '80', 'Epochs': '10'}
{'State': 'GEN_TOKEN', 'Name': 'CSR', 'Project': 'IMG_REC', 'TOKEN_ID': 'csr468'}
Mon Jan 11 00:16:47 2021 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request /imgrecog (ip 157.45.134.15) !!!
Mon Jan 11 00:16:47 2021 - uwsgi_response_writev_headers_and_body_do(): Broken pipe [core/writer.c line 306] during POST /imgrecog (157.45.134.15)
OSError: write error
[pid: 725|app: 0|req: 5/14] 157.45.134.15 () {60 vars in 1060 bytes} [Mon Jan 11 00:15:25 2021] POST /imgrecog => generated 0 bytes in 82496 msecs (HTTP/1.1 200) 4 headers in 0 bytes (0 switches on core 0)
[pid: 725|app: 0|req: 6/15] 157.45.134.15 () {54 vars in 952 bytes} [Mon Jan 11 00:16:47 2021] OPTIONS /hello => generated 0 bytes in 0 msecs (HTTP/1.1 200) 7 headers in 336 bytes (0 switches on core 0)
Epoch [0], last_lr: 0.0000, train_loss: 0.8381, val_loss: 0.7306, val_score: 0.3333
[2021-01-11 00:16:48,003] ERROR in app: Exception on /imgrecog [POST]
Traceback (most recent call last):
  File "/home/ubuntu/venv/lib/python3.8/site-packages/flask/app.py", line 2447, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/ubuntu/venv/lib/python3.8/site-packages/flask/app.py", line 1952, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/ubuntu/venv/lib/python3.8/site-packages/flask_cors/extension.py", line 165, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "/home/ubuntu/venv/lib/python3.8/site-packages/flask_cors/extension.py", line 165, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "/home/ubuntu/venv/lib/python3.8/site-packages/flask/app.py", line 1821, in handle_user_exception
    reraise(exc_type, exc_value, tb)
  File "/home/ubuntu/venv/lib/python3.8/site-packages/flask/_compat.py", line 39, in reraise
    raise value
  File "/home/ubuntu/venv/lib/python3.8/site-packages/flask/app.py", line 1950, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/ubuntu/venv/lib/python3.8/site-packages/flask/app.py", line 1936, in dispatch_request
    return self.view_functions[rule.endpoint](**req.view_args)
  File "./app.py", line 45, in imgRecog
    imageRecognision(ID, epochs, Ratio)
  File "./imageRecognision.py", line 78, in imageRecognision
    history += fit_one_cycle(epochs, max_lr, model, train_dl, val_dl,
  File "./train.py", line 36, in fit_one_cycle
    for batch in train_loader:
  File "./dataloader.py", line 55, in __iter__
    for b in self.dl:
  File "/home/ubuntu/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 435, in __next__
    data = self._next_data()
  File "/home/ubuntu/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 475, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/ubuntu/venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ubuntu/venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ubuntu/venv/lib/python3.8/site-packages/torch/utils/data/dataset.py", line 272, in __getitem__
    return self.dataset[self.indices[idx]]
  File "/home/ubuntu/venv/lib/python3.8/site-packages/torchvision/datasets/folder.py", line 151, in __getitem__
    sample = self.loader(path)
  File "/home/ubuntu/venv/lib/python3.8/site-packages/torchvision/datasets/folder.py", line 188, in default_loader
    return pil_loader(path)
  File "/home/ubuntu/venv/lib/python3.8/site-packages/torchvision/datasets/folder.py", line 168, in pil_loader
    with open(path, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'csr468/dataset/CSR/3.jpg'
Mon Jan 11 00:16:48 2021 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request /imgrecog (ip 157.45.134.15) !!!
Mon Jan 11 00:16:48 2021 - uwsgi_response_writev_headers_and_body_do(): Broken pipe [core/writer.c line 306] during POST /imgrecog (157.45.134.15)
OSError: write error
[pid: 727|app: 0|req: 4/16] 157.45.134.15 () {60 vars in 1060 bytes} [Mon Jan 11 00:16:39 2021] POST /imgrecog => generated 0 bytes in 8617 msecs (HTTP/1.1 500) 4 headers in 0 bytes (0 switches on core 0)
[2021-01-11 00:16:48,006] ERROR in app: Exception on /imgrecog [POST]
Traceback (most recent call last):
  File "/home/ubuntu/venv/lib/python3.8/site-packages/flask/app.py", line 2447, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/ubuntu/venv/lib/python3.8/site-packages/flask/app.py", line 1952, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/ubuntu/venv/lib/python3.8/site-packages/flask_cors/extension.py", line 165, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "/home/ubuntu/venv/lib/python3.8/site-packages/flask_cors/extension.py", line 165, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "/home/ubuntu/venv/lib/python3.8/site-packages/flask/app.py", line 1821, in handle_user_exception
    reraise(exc_type, exc_value, tb)
  File "/home/ubuntu/venv/lib/python3.8/site-packages/flask/_compat.py", line 39, in reraise
    raise value
  File "/home/ubuntu/venv/lib/python3.8/site-packages/flask/app.py", line 1950, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/ubuntu/venv/lib/python3.8/site-packages/flask/app.py", line 1936, in dispatch_request
    return self.view_functions[rule.endpoint](**req.view_args)
  File "./app.py", line 45, in imgRecog
    imageRecognision(ID, epochs, Ratio)
  File "./imageRecognision.py", line 78, in imageRecognision
    history += fit_one_cycle(epochs, max_lr, model, train_dl, val_dl,
  File "./train.py", line 55, in fit_one_cycle
    result = evaluate(model, val_loader)
  File "/home/ubuntu/venv/lib/python3.8/site-packages/torch/autograd/grad_mode.py", line 26, in decorate_context
    return func(*args, **kwargs)
  File "./train.py", line 8, in evaluate
    outputs = [model.validation_step(batch) for batch in val_loader]
  File "./train.py", line 8, in <listcomp>
    outputs = [model.validation_step(batch) for batch in val_loader]
  File "./dataloader.py", line 55, in __iter__
    for b in self.dl:
  File "/home/ubuntu/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 435, in __next__
    data = self._next_data()
  File "/home/ubuntu/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 475, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/ubuntu/venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ubuntu/venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ubuntu/venv/lib/python3.8/site-packages/torch/utils/data/dataset.py", line 272, in __getitem__
    return self.dataset[self.indices[idx]]
  File "/home/ubuntu/venv/lib/python3.8/site-packages/torchvision/datasets/folder.py", line 151, in __getitem__
    sample = self.loader(path)
  File "/home/ubuntu/venv/lib/python3.8/site-packages/torchvision/datasets/folder.py", line 188, in default_loader
    return pil_loader(path)
  File "/home/ubuntu/venv/lib/python3.8/site-packages/torchvision/datasets/folder.py", line 168, in pil_loader
    with open(path, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'csr468/dataset/CSR/9.jpg'
Mon Jan 11 00:16:48 2021 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request /imgrecog (ip 157.45.134.15) !!!
Mon Jan 11 00:16:48 2021 - uwsgi_response_writev_headers_and_body_do(): Broken pipe [core/writer.c line 306] during POST /imgrecog (157.45.134.15)
OSError: write error
[pid: 724|app: 0|req: 4/17] 157.45.134.15 () {60 vars in 1060 bytes} [Mon Jan 11 00:16:39 2021] POST /imgrecog => generated 0 bytes in 8606 msecs (HTTP/1.1 500) 4 headers in 0 bytes (0 switches on core 0)
terminate called after throwing an instance of 'c10::Error'
  what():  [enforce fail at inline_container.cc:380] . PytorchStreamWriter failed writing file version: file write failed
frame #0: c10::ThrowEnforceNotMet(char const*, int, char const*, std::string const&, void const*) + 0x47 (0x7f1b033f46a7 in /home/ubuntu/venv/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: caffe2::serialize::PyTorchStreamWriter::valid(char const*, char const*) + 0xa2 (0x7f1b4275bc72 in /home/ubuntu/venv/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)
frame #2: caffe2::serialize::PyTorchStreamWriter::writeRecord(std::string const&, void const*, unsigned long, bool) + 0xbf (0x7f1b4275c61f in /home/ubuntu/venv/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)
frame #3: caffe2::serialize::PyTorchStreamWriter::writeEndOfFile() + 0xe1 (0x7f1b4275d141 in /home/ubuntu/venv/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)
frame #4: caffe2::serialize::PyTorchStreamWriter::~PyTorchStreamWriter() + 0x115 (0x7f1b4275d935 in /home/ubuntu/venv/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)
frame #5: <unknown function> + 0x3132245 (0x7f1b43bf4245 in /home/ubuntu/venv/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)
frame #6: torch::jit::ExportModule(torch::jit::Module const&, std::string const&, std::unordered_map<std::string, std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<std::string const, std::string> > > const&, bool, bool) + 0x374 (0x7f1b43bf3114 in /home/ubuntu/venv/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)
frame #7: <unknown function> + 0x725a34 (0x7f1b51effa34 in /home/ubuntu/venv/lib/python3.8/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x2c4346 (0x7f1b51a9e346 in /home/ubuntu/venv/lib/python3.8/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
frame #40: python_call + 0x16 (0x5652316eb7e6 in /home/ubuntu/venv/bin/uwsgi)
frame #41: uwsgi_request_wsgi + 0x115 (0x5652316edbb5 in /home/ubuntu/venv/bin/uwsgi)
frame #42: wsgi_req_recv + 0x97 (0x565231688707 in /home/ubuntu/venv/bin/uwsgi)
frame #43: simple_loop_run + 0xc4 (0x5652316d3bf4 in /home/ubuntu/venv/bin/uwsgi)
frame #44: simple_loop + 0x14 (0x5652316d39d4 in /home/ubuntu/venv/bin/uwsgi)
frame #45: uwsgi_ignition + 0x2a4 (0x5652316d8504 in /home/ubuntu/venv/bin/uwsgi)
frame #46: uwsgi_worker_run + 0x276 (0x5652316dcbc6 in /home/ubuntu/venv/bin/uwsgi)
frame #47: uwsgi_run + 0x454 (0x5652316dd144 in /home/ubuntu/venv/bin/uwsgi)
frame #48: <unknown function> + 0x3bd84 (0x565231687d84 in /home/ubuntu/venv/bin/uwsgi)
frame #49: __libc_start_main + 0xf3 (0x7f1b549860b3 in /lib/x86_64-linux-gnu/libc.so.6)
frame #50: _start + 0x2e (0x565231687dbe in /home/ubuntu/venv/bin/uwsgi)

DAMN ! worker 4 (pid: 726) died, killed by signal 6 :( trying respawn ...
Respawned uWSGI worker 4 (new pid: 1274)
[2021-01-11 00:17:27,583] ERROR in app: Exception on /imgrecog [POST]
Traceback (most recent call last):
  File "/home/ubuntu/venv/lib/python3.8/site-packages/flask/app.py", line 2447, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/ubuntu/venv/lib/python3.8/site-packages/flask/app.py", line 1952, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/ubuntu/venv/lib/python3.8/site-packages/flask_cors/extension.py", line 165, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "/home/ubuntu/venv/lib/python3.8/site-packages/flask_cors/extension.py", line 165, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "/home/ubuntu/venv/lib/python3.8/site-packages/flask/app.py", line 1821, in handle_user_exception
    reraise(exc_type, exc_value, tb)
  File "/home/ubuntu/venv/lib/python3.8/site-packages/flask/_compat.py", line 39, in reraise
    raise value
  File "/home/ubuntu/venv/lib/python3.8/site-packages/flask/app.py", line 1950, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/ubuntu/venv/lib/python3.8/site-packages/flask/app.py", line 1936, in dispatch_request
    return self.view_functions[rule.endpoint](**req.view_args)
  File "./app.py", line 45, in imgRecog
    imageRecognision(ID, epochs, Ratio)
  File "./imageRecognision.py", line 97, in imageRecognision
    with open(moduleName+"/output.json", "w") as outfile:
FileNotFoundError: [Errno 2] No such file or directory: 'csr468/output.json'
Mon Jan 11 00:17:27 2021 - SIGPIPE: writing to a closed pipe/socket/fd (probably the client disconnected) on request /imgrecog (ip 157.45.134.15) !!!
Mon Jan 11 00:17:27 2021 - uwsgi_response_writev_headers_and_body_do(): Broken pipe [core/writer.c line 306] during POST /imgrecog (157.45.134.15)
OSError: write error
[pid: 723|app: 0|req: 1/18] 157.45.134.15 () {60 vars in 1060 bytes} [Mon Jan 11 00:15:25 2021] POST /imgrecog => generated 0 bytes in 122321 msecs (HTTP/1.1 500) 4 headers in 0 bytes (0 switches on core 0)
<_io.BytesIO object at 0x7f1af1383a40>
1
csr468
{'State': 'MODEL_READY', 'prediction': 'NORML'}
[pid: 727|app: 0|req: 5/19] 13.235.216.243 () {42 vars in 567 bytes} [Mon Jan 11 00:19:14 2021] POST /imginfer => generated 45 bytes in 766 msecs (HTTP/1.1 200) 2 headers in 71 bytes (1 switches on core 0)
SIGINT/SIGQUIT received...killing workers...
worker 4 buried after 1 seconds
worker 1 buried after 2 seconds
worker 2 buried after 2 seconds
worker 5 buried after 2 seconds
Mon Jan 11 00:34:07 2021 - worker 3 (pid: 725) is taking too much time to die...NO MERCY !!!
worker 3 buried after 1 seconds
goodbye to uWSGI.
VACUUM: unix socket enigma.sock removed.
*** Starting uWSGI 2.0.19.1 (64bit) on [Mon Jan 11 00:35:14 2021] ***
compiled with version: 9.3.0 on 10 January 2021 08:34:57
os: Linux-5.4.0-1029-aws #30-Ubuntu SMP Tue Oct 20 10:06:38 UTC 2020
nodename: ip-172-31-29-101
machine: x86_64
clock source: unix
detected number of CPU cores: 2
current working directory: /home/ubuntu/enigma
detected binary path: /home/ubuntu/venv/bin/uwsgi
!!! no internal routing support, rebuild with pcre support !!!
your processes number limit is 31409
your memory page size is 4096 bytes
detected max file descriptor number: 1024
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 bound to UNIX address enigma.sock fd 3
Python version: 3.8.5 (default, Jul 28 2020, 12:59:40)  [GCC 9.3.0]
Python main interpreter initialized at 0x55c665682cc0
python threads support enabled
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 437520 bytes (427 KB) for 5 cores
*** Operational MODE: preforking ***
WSGI app 0 (mountpoint='') ready in 4 seconds on interpreter 0x55c665682cc0 pid: 457 (default app)
*** uWSGI is running in multiple interpreter mode ***
spawned uWSGI master process (pid: 457)
spawned uWSGI worker 1 (pid: 729, cores: 1)
spawned uWSGI worker 2 (pid: 730, cores: 1)
spawned uWSGI worker 3 (pid: 731, cores: 1)
spawned uWSGI worker 4 (pid: 732, cores: 1)
spawned uWSGI worker 5 (pid: 733, cores: 1)
[pid: 733|app: 0|req: 1/1] 192.241.225.58 () {36 vars in 424 bytes} [Mon Jan 11 00:42:19 2021] GET /login => generated 232 bytes in 5 msecs (HTTP/1.1 404) 2 headers in 87 bytes (1 switches on core 0)
[pid: 731|app: 0|req: 1/2] 13.57.59.209 () {36 vars in 522 bytes} [Mon Jan 11 02:22:38 2021] GET / => generated 232 bytes in 3 msecs (HTTP/1.1 404) 2 headers in 87 bytes (1 switches on core 0)
[pid: 732|app: 0|req: 1/3] 39.96.138.251 () {38 vars in 565 bytes} [Mon Jan 11 03:43:48 2021] GET /dns-query?dns=AAABAAABAAAAAAAAA3d3dwViYWlkdQNjb20AAAEAAQ => generated 232 bytes in 3 msecs (HTTP/1.1 404) 2 headers in 87 bytes (1 switches on core 0)
[pid: 732|app: 0|req: 2/4] 193.118.53.210 () {36 vars in 508 bytes} [Mon Jan 11 04:25:10 2021] GET / => generated 232 bytes in 0 msecs (HTTP/1.1 404) 2 headers in 87 bytes (1 switches on core 0)
[pid: 732|app: 0|req: 3/5] 157.45.133.206 () {54 vars in 953 bytes} [Mon Jan 11 04:29:16 2021] OPTIONS /hello => generated 0 bytes in 1 msecs (HTTP/1.1 200) 7 headers in 336 bytes (0 switches on core 0)
[pid: 730|app: 0|req: 1/6] 157.45.133.206 () {60 vars in 1055 bytes} [Mon Jan 11 04:29:16 2021] POST /hello => generated 16 bytes in 3 msecs (HTTP/1.1 200) 4 headers in 158 bytes (2 switches on core 0)
[pid: 730|app: 0|req: 2/7] 157.45.133.206 () {54 vars in 959 bytes} [Mon Jan 11 04:29:22 2021] OPTIONS /imgrecog => generated 0 bytes in 1 msecs (HTTP/1.1 200) 7 headers in 336 bytes (0 switches on core 0)
{'Project': 'IMG_REC', 'TOKEN_ID': 'kuttu080', 'Ratio': '80', 'Epochs': '10'}
/home/ubuntu/venv/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
Using cache found in /home/ubuntu/.cache/torch/hub/pytorch_vision_v0.6.0
Epoch [0], last_lr: 0.0000, train_loss: 0.6646, val_loss: 0.6649, val_score: 0.5000
Epoch [1], last_lr: 0.0002, train_loss: 0.8251, val_loss: 0.6482, val_score: 1.0000
Epoch [2], last_lr: 0.0004, train_loss: 0.6741, val_loss: 0.6348, val_score: 1.0000
Epoch [3], last_lr: 0.0006, train_loss: 0.7146, val_loss: 0.5960, val_score: 1.0000
Epoch [4], last_lr: 0.0008, train_loss: 0.6709, val_loss: 0.5381, val_score: 1.0000
Epoch [5], last_lr: 0.0010, train_loss: 0.6482, val_loss: 0.4725, val_score: 1.0000
Epoch [6], last_lr: 0.0012, train_loss: 0.5176, val_loss: 0.3971, val_score: 1.0000
Epoch [7], last_lr: 0.0014, train_loss: 0.4199, val_loss: 0.3122, val_score: 1.0000
Epoch [8], last_lr: 0.0016, train_loss: 0.2754, val_loss: 0.2396, val_score: 1.0000
Epoch [9], last_lr: 0.0018, train_loss: 0.2096, val_loss: 0.1808, val_score: 1.0000
best accuracy = 1.0
{'Project': 'IMG_REC', 'TOKEN_ID': 'kuttu080', 'Ratio': '80', 'Epochs': '10'}
{'State': 'GEN_TOKEN', 'Name': 'kuttu', 'Project': 'IMG_REC', 'TOKEN_ID': 'kuttu080'}
[pid: 730|app: 0|req: 3/8] 157.45.133.206 () {60 vars in 1061 bytes} [Mon Jan 11 04:29:22 2021] POST /imgrecog => generated 16 bytes in 12672 msecs (HTTP/1.1 200) 4 headers in 158 bytes (1 switches on core 0)
<_io.BytesIO object at 0x7fc232878a90>
1
kuttu080
{'State': 'MODEL_READY', 'prediction': 'ammu'}
[pid: 733|app: 0|req: 2/9] 13.232.216.206 () {42 vars in 565 bytes} [Mon Jan 11 04:30:09 2021] POST /imginfer => generated 44 bytes in 1435 msecs (HTTP/1.1 200) 2 headers in 71 bytes (1 switches on core 0)
<_io.BytesIO object at 0x7fc23284c6d0>
1
kuttu080
{'State': 'MODEL_READY', 'prediction': 'chinnu'}
[pid: 732|app: 0|req: 4/10] 13.232.216.206 () {42 vars in 563 bytes} [Mon Jan 11 04:30:28 2021] POST /imginfer => generated 46 bytes in 1094 msecs (HTTP/1.1 200) 2 headers in 71 bytes (1 switches on core 0)
[pid: 733|app: 0|req: 3/11] 38.145.84.144 () {54 vars in 936 bytes} [Mon Jan 11 04:40:18 2021] GET / => generated 232 bytes in 1 msecs (HTTP/1.1 404) 2 headers in 87 bytes (1 switches on core 0)
[pid: 733|app: 0|req: 4/12] 45.155.205.108 () {40 vars in 733 bytes} [Mon Jan 11 05:46:50 2021] POST /vendor/phpunit/phpunit/src/Util/PHP/eval-stdin.php => generated 232 bytes in 0 msecs (HTTP/1.1 404) 2 headers in 87 bytes (1 switches on core 0)
[pid: 730|app: 0|req: 4/13] 45.155.205.108 () {36 vars in 741 bytes} [Mon Jan 11 05:46:51 2021] GET /index.php?s=/Index/\think\app/invokefunction&function=call_user_func_array&vars[0]=md5&vars[1][]=HelloThinkPHP21 => generated 232 bytes in 0 msecs (HTTP/1.1 404) 2 headers in 87 bytes (1 switches on core 0)
[pid: 732|app: 0|req: 5/14] 45.155.205.108 () {36 vars in 608 bytes} [Mon Jan 11 05:46:54 2021] GET /wp-content/plugins/wp-file-manager/readme.txt => generated 232 bytes in 0 msecs (HTTP/1.1 404) 2 headers in 87 bytes (2 switches on core 0)
[pid: 731|app: 0|req: 2/15] 45.155.205.108 () {36 vars in 534 bytes} [Mon Jan 11 05:46:54 2021] GET /console/ => generated 232 bytes in 0 msecs (HTTP/1.1 404) 2 headers in 87 bytes (2 switches on core 0)
[pid: 729|app: 0|req: 1/16] 45.155.205.108 () {40 vars in 657 bytes} [Mon Jan 11 05:46:56 2021] POST /Autodiscover/Autodiscover.xml => generated 232 bytes in 3 msecs (HTTP/1.1 404) 2 headers in 87 bytes (2 switches on core 0)
[pid: 733|app: 0|req: 5/17] 45.155.205.108 () {36 vars in 577 bytes} [Mon Jan 11 05:46:57 2021] GET /?XDEBUG_SESSION_START=phpstorm => generated 232 bytes in 0 msecs (HTTP/1.1 404) 2 headers in 87 bytes (2 switches on core 0)
[pid: 730|app: 0|req: 5/18] 45.155.205.108 () {42 vars in 701 bytes} [Mon Jan 11 05:46:59 2021] POST /mifs/.;/services/LogService => generated 232 bytes in 0 msecs (HTTP/1.1 404) 2 headers in 87 bytes (2 switches on core 0)
[pid: 731|app: 0|req: 3/19] 45.155.205.108 () {38 vars in 645 bytes} [Mon Jan 11 05:46:59 2021] GET /vendor/phpunit/phpunit/src/Util/PHP/eval-stdin.php => generated 232 bytes in 0 msecs (HTTP/1.1 404) 2 headers in 87 bytes (2 switches on core 0)
[pid: 732|app: 0|req: 6/20] 45.155.205.108 () {40 vars in 631 bytes} [Mon Jan 11 05:47:01 2021] POST /api/jsonws/invoke => generated 232 bytes in 0 msecs (HTTP/1.1 404) 2 headers in 87 bytes (2 switches on core 0)
[pid: 733|app: 0|req: 6/21] 192.241.222.91 () {36 vars in 444 bytes} [Mon Jan 11 07:18:06 2021] GET /actuator/health => generated 232 bytes in 0 msecs (HTTP/1.1 404) 2 headers in 87 bytes (1 switches on core 0)
[pid: 733|app: 0|req: 7/22] 40.86.206.98 () {38 vars in 542 bytes} [Mon Jan 11 07:22:48 2021] GET /.env => generated 232 bytes in 0 msecs (HTTP/1.1 404) 2 headers in 87 bytes (1 switches on core 0)
[pid: 729|app: 0|req: 2/23] 40.86.206.98 () {42 vars in 649 bytes} [Mon Jan 11 07:22:49 2021] POST / => generated 232 bytes in 0 msecs (HTTP/1.1 404) 2 headers in 87 bytes (1 switches on core 0)
[pid: 733|app: 0|req: 8/24] 185.189.12.23 () {32 vars in 356 bytes} [Mon Jan 11 07:27:43 2021] GET / => generated 232 bytes in 0 msecs (HTTP/1.1 404) 2 headers in 87 bytes (2 switches on core 0)
